{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usnjLlIhv8LW",
        "outputId": "b11f38d7-7b57-4f70-bb83-c170dffe7e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================================================================================================\n",
            "A2 Pairwise Activity+Subject Transfer Results (4C2 pairs, LOSO-subject inside each pair)\n",
            "==============================================================================================================\n",
            "\n",
            "1. Waist bends forward -> Frontal elevation of arms  |  MAE=6.008\n",
            "subject1 | GT=20 | Pred(win)=27.00 | Diff=+7.00 | k_hat(full)=1.02 | phase_entropy(full)=0.043\n",
            "subject2 | GT=20 | Pred(win)=29.74 | Diff=+9.74 | k_hat(full)=1.06 | phase_entropy(full)=0.123\n",
            "subject3 | GT=20 | Pred(win)=22.93 | Diff=+2.93 | k_hat(full)=1.03 | phase_entropy(full)=0.069\n",
            "subject4 | GT=20 | Pred(win)=28.34 | Diff=+8.34 | k_hat(full)=1.02 | phase_entropy(full)=0.047\n",
            "subject5 | GT=20 | Pred(win)=26.35 | Diff=+6.35 | k_hat(full)=1.02 | phase_entropy(full)=0.051\n",
            "subject6 | GT=20 | Pred(win)=14.95 | Diff=-5.05 | k_hat(full)=1.01 | phase_entropy(full)=0.026\n",
            "subject7 | GT=20 | Pred(win)=21.33 | Diff=+1.33 | k_hat(full)=1.02 | phase_entropy(full)=0.042\n",
            "subject8 | GT=19 | Pred(win)=33.73 | Diff=+14.73 | k_hat(full)=1.01 | phase_entropy(full)=0.033\n",
            "subject9 | GT=19 | Pred(win)=23.55 | Diff=+4.55 | k_hat(full)=1.01 | phase_entropy(full)=0.037\n",
            "subject10 | GT=20 | Pred(win)=20.06 | Diff=+0.06 | k_hat(full)=1.01 | phase_entropy(full)=0.039\n",
            "\n",
            "2. Frontal elevation of arms -> Waist bends forward  |  MAE=4.068\n",
            "subject1 | GT=21 | Pred(win)=17.93 | Diff=-3.07 | k_hat(full)=1.01 | phase_entropy(full)=0.027\n",
            "subject2 | GT=19 | Pred(win)=22.59 | Diff=+3.59 | k_hat(full)=1.04 | phase_entropy(full)=0.079\n",
            "subject3 | GT=21 | Pred(win)=24.22 | Diff=+3.22 | k_hat(full)=1.03 | phase_entropy(full)=0.081\n",
            "subject4 | GT=20 | Pred(win)=25.33 | Diff=+5.33 | k_hat(full)=1.02 | phase_entropy(full)=0.066\n",
            "subject5 | GT=20 | Pred(win)=17.55 | Diff=-2.45 | k_hat(full)=1.01 | phase_entropy(full)=0.032\n",
            "subject6 | GT=20 | Pred(win)=14.82 | Diff=-5.18 | k_hat(full)=1.01 | phase_entropy(full)=0.044\n",
            "subject7 | GT=20 | Pred(win)=21.14 | Diff=+1.14 | k_hat(full)=1.04 | phase_entropy(full)=0.087\n",
            "subject8 | GT=21 | Pred(win)=15.76 | Diff=-5.24 | k_hat(full)=1.01 | phase_entropy(full)=0.038\n",
            "subject9 | GT=21 | Pred(win)=13.65 | Diff=-7.35 | k_hat(full)=1.01 | phase_entropy(full)=0.038\n",
            "subject10 | GT=20 | Pred(win)=15.90 | Diff=-4.10 | k_hat(full)=1.08 | phase_entropy(full)=0.154\n",
            "\n",
            "3. Waist bends forward -> Knees bending  |  MAE=4.879\n",
            "subject1 | GT=20 | Pred(win)=27.64 | Diff=+7.64 | k_hat(full)=1.01 | phase_entropy(full)=0.026\n",
            "subject2 | GT=21 | Pred(win)=27.26 | Diff=+6.26 | k_hat(full)=1.03 | phase_entropy(full)=0.062\n",
            "subject3 | GT=21 | Pred(win)=27.49 | Diff=+6.49 | k_hat(full)=1.01 | phase_entropy(full)=0.026\n",
            "subject4 | GT=19 | Pred(win)=31.72 | Diff=+12.72 | k_hat(full)=1.01 | phase_entropy(full)=0.036\n",
            "subject5 | GT=20 | Pred(win)=24.32 | Diff=+4.32 | k_hat(full)=1.01 | phase_entropy(full)=0.026\n",
            "subject6 | GT=20 | Pred(win)=18.33 | Diff=-1.67 | k_hat(full)=1.00 | phase_entropy(full)=0.010\n",
            "subject7 | GT=21 | Pred(win)=19.25 | Diff=-1.75 | k_hat(full)=1.02 | phase_entropy(full)=0.060\n",
            "subject8 | GT=21 | Pred(win)=21.53 | Diff=+0.53 | k_hat(full)=1.01 | phase_entropy(full)=0.031\n",
            "subject9 | GT=21 | Pred(win)=22.39 | Diff=+1.39 | k_hat(full)=1.02 | phase_entropy(full)=0.057\n",
            "subject10 | GT=12 | Pred(win)=18.03 | Diff=+6.03 | k_hat(full)=1.03 | phase_entropy(full)=0.073\n",
            "\n",
            "4. Knees bending -> Waist bends forward  |  MAE=5.143\n",
            "subject1 | GT=21 | Pred(win)=15.35 | Diff=-5.65 | k_hat(full)=1.03 | phase_entropy(full)=0.082\n",
            "subject2 | GT=19 | Pred(win)=17.88 | Diff=-1.12 | k_hat(full)=1.06 | phase_entropy(full)=0.114\n",
            "subject3 | GT=21 | Pred(win)=18.74 | Diff=-2.26 | k_hat(full)=1.03 | phase_entropy(full)=0.081\n",
            "subject4 | GT=20 | Pred(win)=22.47 | Diff=+2.47 | k_hat(full)=1.41 | phase_entropy(full)=0.325\n",
            "subject5 | GT=20 | Pred(win)=12.72 | Diff=-7.28 | k_hat(full)=1.04 | phase_entropy(full)=0.102\n",
            "subject6 | GT=20 | Pred(win)=12.57 | Diff=-7.43 | k_hat(full)=1.02 | phase_entropy(full)=0.048\n",
            "subject7 | GT=20 | Pred(win)=17.58 | Diff=-2.42 | k_hat(full)=1.02 | phase_entropy(full)=0.051\n",
            "subject8 | GT=21 | Pred(win)=10.12 | Diff=-10.88 | k_hat(full)=1.02 | phase_entropy(full)=0.058\n",
            "subject9 | GT=21 | Pred(win)=13.29 | Diff=-7.71 | k_hat(full)=1.02 | phase_entropy(full)=0.070\n",
            "subject10 | GT=20 | Pred(win)=15.79 | Diff=-4.21 | k_hat(full)=1.02 | phase_entropy(full)=0.051\n",
            "\n",
            "5. Waist bends forward -> Jump front & back  |  MAE=11.701\n",
            "subject1 | GT=20 | Pred(win)=9.34 | Diff=-10.66 | k_hat(full)=1.02 | phase_entropy(full)=0.053\n",
            "subject2 | GT=22 | Pred(win)=8.71 | Diff=-13.29 | k_hat(full)=1.02 | phase_entropy(full)=0.042\n",
            "subject3 | GT=21 | Pred(win)=9.31 | Diff=-11.69 | k_hat(full)=1.01 | phase_entropy(full)=0.024\n",
            "subject4 | GT=21 | Pred(win)=9.54 | Diff=-11.46 | k_hat(full)=1.02 | phase_entropy(full)=0.042\n",
            "subject5 | GT=20 | Pred(win)=7.35 | Diff=-12.65 | k_hat(full)=1.03 | phase_entropy(full)=0.079\n",
            "subject6 | GT=21 | Pred(win)=8.49 | Diff=-12.51 | k_hat(full)=1.01 | phase_entropy(full)=0.023\n",
            "subject7 | GT=19 | Pred(win)=8.74 | Diff=-10.26 | k_hat(full)=1.01 | phase_entropy(full)=0.038\n",
            "subject8 | GT=20 | Pred(win)=7.70 | Diff=-12.30 | k_hat(full)=1.01 | phase_entropy(full)=0.021\n",
            "subject9 | GT=20 | Pred(win)=8.29 | Diff=-11.71 | k_hat(full)=1.02 | phase_entropy(full)=0.051\n",
            "subject10 | GT=20 | Pred(win)=9.52 | Diff=-10.48 | k_hat(full)=1.01 | phase_entropy(full)=0.021\n",
            "\n",
            "6. Jump front & back -> Waist bends forward  |  MAE=30.071\n",
            "subject1 | GT=21 | Pred(win)=49.57 | Diff=+28.57 | k_hat(full)=2.14 | phase_entropy(full)=0.836\n",
            "subject2 | GT=19 | Pred(win)=58.42 | Diff=+39.42 | k_hat(full)=1.95 | phase_entropy(full)=0.767\n",
            "subject3 | GT=21 | Pred(win)=67.30 | Diff=+46.30 | k_hat(full)=1.96 | phase_entropy(full)=0.898\n",
            "subject4 | GT=20 | Pred(win)=65.41 | Diff=+45.41 | k_hat(full)=2.34 | phase_entropy(full)=0.952\n",
            "subject5 | GT=20 | Pred(win)=51.68 | Diff=+31.68 | k_hat(full)=2.14 | phase_entropy(full)=0.817\n",
            "subject6 | GT=20 | Pred(win)=38.47 | Diff=+18.47 | k_hat(full)=2.80 | phase_entropy(full)=0.970\n",
            "subject7 | GT=20 | Pred(win)=49.07 | Diff=+29.07 | k_hat(full)=2.88 | phase_entropy(full)=0.993\n",
            "subject8 | GT=21 | Pred(win)=38.08 | Diff=+17.08 | k_hat(full)=2.03 | phase_entropy(full)=0.806\n",
            "subject9 | GT=21 | Pred(win)=39.35 | Diff=+18.35 | k_hat(full)=2.35 | phase_entropy(full)=0.835\n",
            "subject10 | GT=20 | Pred(win)=46.35 | Diff=+26.35 | k_hat(full)=2.20 | phase_entropy(full)=0.850\n",
            "\n",
            "7. Frontal elevation of arms -> Knees bending  |  MAE=3.991\n",
            "subject1 | GT=20 | Pred(win)=27.97 | Diff=+7.97 | k_hat(full)=1.01 | phase_entropy(full)=0.026\n",
            "subject2 | GT=21 | Pred(win)=23.12 | Diff=+2.12 | k_hat(full)=1.02 | phase_entropy(full)=0.053\n",
            "subject3 | GT=21 | Pred(win)=28.41 | Diff=+7.41 | k_hat(full)=1.02 | phase_entropy(full)=0.052\n",
            "subject4 | GT=19 | Pred(win)=23.66 | Diff=+4.66 | k_hat(full)=1.02 | phase_entropy(full)=0.062\n",
            "subject5 | GT=20 | Pred(win)=22.69 | Diff=+2.69 | k_hat(full)=1.02 | phase_entropy(full)=0.047\n",
            "subject6 | GT=20 | Pred(win)=16.46 | Diff=-3.54 | k_hat(full)=1.01 | phase_entropy(full)=0.037\n",
            "subject7 | GT=21 | Pred(win)=19.31 | Diff=-1.69 | k_hat(full)=1.03 | phase_entropy(full)=0.074\n",
            "subject8 | GT=21 | Pred(win)=19.89 | Diff=-1.11 | k_hat(full)=1.02 | phase_entropy(full)=0.056\n",
            "subject9 | GT=21 | Pred(win)=21.53 | Diff=+0.53 | k_hat(full)=1.03 | phase_entropy(full)=0.073\n",
            "subject10 | GT=12 | Pred(win)=20.19 | Diff=+8.19 | k_hat(full)=1.04 | phase_entropy(full)=0.088\n",
            "\n",
            "8. Knees bending -> Frontal elevation of arms  |  MAE=3.442\n",
            "subject1 | GT=20 | Pred(win)=27.09 | Diff=+7.09 | k_hat(full)=1.04 | phase_entropy(full)=0.094\n",
            "subject2 | GT=20 | Pred(win)=22.32 | Diff=+2.32 | k_hat(full)=1.06 | phase_entropy(full)=0.130\n",
            "subject3 | GT=20 | Pred(win)=19.94 | Diff=-0.06 | k_hat(full)=1.06 | phase_entropy(full)=0.125\n",
            "subject4 | GT=20 | Pred(win)=17.84 | Diff=-2.16 | k_hat(full)=1.75 | phase_entropy(full)=0.442\n",
            "subject5 | GT=20 | Pred(win)=20.84 | Diff=+0.84 | k_hat(full)=1.04 | phase_entropy(full)=0.091\n",
            "subject6 | GT=20 | Pred(win)=11.68 | Diff=-8.32 | k_hat(full)=1.04 | phase_entropy(full)=0.094\n",
            "subject7 | GT=20 | Pred(win)=18.16 | Diff=-1.84 | k_hat(full)=1.02 | phase_entropy(full)=0.057\n",
            "subject8 | GT=19 | Pred(win)=26.10 | Diff=+7.10 | k_hat(full)=1.03 | phase_entropy(full)=0.078\n",
            "subject9 | GT=19 | Pred(win)=19.90 | Diff=+0.90 | k_hat(full)=1.03 | phase_entropy(full)=0.062\n",
            "subject10 | GT=20 | Pred(win)=16.22 | Diff=-3.78 | k_hat(full)=1.02 | phase_entropy(full)=0.048\n",
            "\n",
            "9. Frontal elevation of arms -> Jump front & back  |  MAE=12.934\n",
            "subject1 | GT=20 | Pred(win)=7.49 | Diff=-12.51 | k_hat(full)=1.02 | phase_entropy(full)=0.041\n",
            "subject2 | GT=22 | Pred(win)=6.98 | Diff=-15.02 | k_hat(full)=1.01 | phase_entropy(full)=0.028\n",
            "subject3 | GT=21 | Pred(win)=7.67 | Diff=-13.33 | k_hat(full)=1.01 | phase_entropy(full)=0.029\n",
            "subject4 | GT=21 | Pred(win)=7.99 | Diff=-13.01 | k_hat(full)=1.01 | phase_entropy(full)=0.036\n",
            "subject5 | GT=20 | Pred(win)=7.36 | Diff=-12.64 | k_hat(full)=1.02 | phase_entropy(full)=0.055\n",
            "subject6 | GT=21 | Pred(win)=7.31 | Diff=-13.69 | k_hat(full)=1.01 | phase_entropy(full)=0.026\n",
            "subject7 | GT=19 | Pred(win)=6.91 | Diff=-12.09 | k_hat(full)=1.01 | phase_entropy(full)=0.040\n",
            "subject8 | GT=20 | Pred(win)=7.39 | Diff=-12.61 | k_hat(full)=1.02 | phase_entropy(full)=0.035\n",
            "subject9 | GT=20 | Pred(win)=7.95 | Diff=-12.05 | k_hat(full)=1.01 | phase_entropy(full)=0.033\n",
            "subject10 | GT=20 | Pred(win)=7.60 | Diff=-12.40 | k_hat(full)=1.01 | phase_entropy(full)=0.030\n",
            "\n",
            "10. Jump front & back -> Frontal elevation of arms  |  MAE=34.015\n",
            "subject1 | GT=20 | Pred(win)=60.15 | Diff=+40.15 | k_hat(full)=2.56 | phase_entropy(full)=0.917\n",
            "subject2 | GT=20 | Pred(win)=60.38 | Diff=+40.38 | k_hat(full)=2.36 | phase_entropy(full)=0.874\n",
            "subject3 | GT=20 | Pred(win)=51.78 | Diff=+31.78 | k_hat(full)=2.52 | phase_entropy(full)=0.979\n",
            "subject4 | GT=20 | Pred(win)=60.73 | Diff=+40.73 | k_hat(full)=2.30 | phase_entropy(full)=0.892\n",
            "subject5 | GT=20 | Pred(win)=53.85 | Diff=+33.85 | k_hat(full)=2.60 | phase_entropy(full)=0.916\n",
            "subject6 | GT=20 | Pred(win)=37.77 | Diff=+17.77 | k_hat(full)=2.74 | phase_entropy(full)=0.973\n",
            "subject7 | GT=20 | Pred(win)=51.00 | Diff=+31.00 | k_hat(full)=2.62 | phase_entropy(full)=0.883\n",
            "subject8 | GT=19 | Pred(win)=58.50 | Diff=+39.50 | k_hat(full)=2.46 | phase_entropy(full)=0.879\n",
            "subject9 | GT=19 | Pred(win)=53.31 | Diff=+34.31 | k_hat(full)=2.61 | phase_entropy(full)=0.925\n",
            "subject10 | GT=20 | Pred(win)=50.67 | Diff=+30.67 | k_hat(full)=2.56 | phase_entropy(full)=0.901\n",
            "\n",
            "11. Knees bending -> Jump front & back  |  MAE=13.532\n",
            "subject1 | GT=20 | Pred(win)=8.45 | Diff=-11.55 | k_hat(full)=1.05 | phase_entropy(full)=0.115\n",
            "subject2 | GT=22 | Pred(win)=6.83 | Diff=-15.17 | k_hat(full)=1.06 | phase_entropy(full)=0.133\n",
            "subject3 | GT=21 | Pred(win)=6.85 | Diff=-14.15 | k_hat(full)=1.07 | phase_entropy(full)=0.154\n",
            "subject4 | GT=21 | Pred(win)=6.53 | Diff=-14.47 | k_hat(full)=1.59 | phase_entropy(full)=0.392\n",
            "subject5 | GT=20 | Pred(win)=5.97 | Diff=-14.03 | k_hat(full)=1.09 | phase_entropy(full)=0.176\n",
            "subject6 | GT=21 | Pred(win)=7.47 | Diff=-13.53 | k_hat(full)=1.08 | phase_entropy(full)=0.144\n",
            "subject7 | GT=19 | Pred(win)=6.83 | Diff=-12.17 | k_hat(full)=1.06 | phase_entropy(full)=0.127\n",
            "subject8 | GT=20 | Pred(win)=6.51 | Diff=-13.49 | k_hat(full)=1.08 | phase_entropy(full)=0.150\n",
            "subject9 | GT=20 | Pred(win)=6.41 | Diff=-13.59 | k_hat(full)=1.08 | phase_entropy(full)=0.149\n",
            "subject10 | GT=20 | Pred(win)=6.82 | Diff=-13.18 | k_hat(full)=1.04 | phase_entropy(full)=0.088\n",
            "\n",
            "12. Jump front & back -> Knees bending  |  MAE=40.088\n",
            "subject1 | GT=20 | Pred(win)=83.72 | Diff=+63.72 | k_hat(full)=1.93 | phase_entropy(full)=0.821\n",
            "subject2 | GT=21 | Pred(win)=58.81 | Diff=+37.81 | k_hat(full)=2.08 | phase_entropy(full)=0.822\n",
            "subject3 | GT=21 | Pred(win)=61.02 | Diff=+40.02 | k_hat(full)=2.00 | phase_entropy(full)=0.859\n",
            "subject4 | GT=19 | Pred(win)=60.18 | Diff=+41.18 | k_hat(full)=2.35 | phase_entropy(full)=0.918\n",
            "subject5 | GT=20 | Pred(win)=63.54 | Diff=+43.54 | k_hat(full)=1.92 | phase_entropy(full)=0.845\n",
            "subject6 | GT=20 | Pred(win)=42.49 | Diff=+22.49 | k_hat(full)=2.54 | phase_entropy(full)=0.974\n",
            "subject7 | GT=21 | Pred(win)=47.89 | Diff=+26.89 | k_hat(full)=2.43 | phase_entropy(full)=0.986\n",
            "subject8 | GT=21 | Pred(win)=44.43 | Diff=+23.43 | k_hat(full)=2.21 | phase_entropy(full)=0.913\n",
            "subject9 | GT=21 | Pred(win)=72.57 | Diff=+51.57 | k_hat(full)=2.22 | phase_entropy(full)=0.862\n",
            "subject10 | GT=12 | Pred(win)=62.23 | Diff=+50.23 | k_hat(full)=2.06 | phase_entropy(full)=0.854\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Overall Avg MAE=14.156 | Std=12.522 | #pair_blocks=12\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "==============================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# A2 Pairwise (4C2) Full Code\n",
        "# - Unseen Activity + Unseen Subject\n",
        "# - For each activity pair (A->B):\n",
        "#     For each test_subject:\n",
        "#       Train on activity A using subjects except test_subject (windowed)\n",
        "#       Test on activity B using ONLY test_subject (windowing inference)\n",
        "#       k_hat / entropy: full-trial 1 forward for 기록\n",
        "# - 4C2=6 pairs, BIDIRECTIONAL=True -> 총 12 pair blocks\n",
        "# - 각 block 안에는 subject1~10 (LOSO) 결과 10줄\n",
        "# - 결과는 마지막에 한 번만 출력\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Strict Seeding\n",
        "# ---------------------------------------------------------------------\n",
        "def set_strict_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Data Loading\n",
        "# ---------------------------------------------------------------------\n",
        "def load_mhealth_dataset(data_dir, target_activities_map, column_names):\n",
        "    full_dataset = {}\n",
        "    file_list = sorted(glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\")))\n",
        "\n",
        "    if not file_list:\n",
        "        print(f\"[Warning] No mHealth logs found in {data_dir}\")\n",
        "        return {}\n",
        "\n",
        "    for file_path in file_list:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        subj_part = file_name.split('.')[0]\n",
        "        try:\n",
        "            subj_id_num = int(''.join(filter(str.isdigit, subj_part)))\n",
        "            subj_key = f\"subject{subj_id_num}\"\n",
        "        except:\n",
        "            subj_key = subj_part\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "            df = df.iloc[:, :len(column_names)]\n",
        "            df.columns = column_names\n",
        "\n",
        "            subj_data = {}\n",
        "            for label_code, activity_name in target_activities_map.items():\n",
        "                activity_df = df[df['activity_id'] == label_code].copy()\n",
        "                if not activity_df.empty:\n",
        "                    subj_data[activity_name] = activity_df.drop(columns=['activity_id'])\n",
        "\n",
        "            full_dataset[subj_key] = subj_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_name}: {e}\")\n",
        "            pass\n",
        "\n",
        "    return full_dataset\n",
        "\n",
        "\n",
        "def prepare_trial_list(label_config, full_data, target_map, feature_map):\n",
        "    \"\"\"\n",
        "    label_config: list of (subj, act_id, gt_count)\n",
        "    return: list of dict trials\n",
        "    \"\"\"\n",
        "    trial_list = []\n",
        "    for subj, act_id, gt_count in label_config:\n",
        "        act_name = target_map.get(act_id)\n",
        "        feats = feature_map.get(act_id)\n",
        "\n",
        "        if subj in full_data and act_name in full_data[subj]:\n",
        "            raw_df = full_data[subj][act_name][feats]\n",
        "            raw_np = raw_df.values.astype(np.float32)\n",
        "\n",
        "            # Z-score (trial-wise)\n",
        "            mean = raw_np.mean(axis=0)\n",
        "            std = raw_np.std(axis=0) + 1e-6\n",
        "            norm_np = (raw_np - mean) / std\n",
        "\n",
        "            trial_list.append({\n",
        "                'data': norm_np,              # (T,C)\n",
        "                'count': float(gt_count),      # trial total count\n",
        "                'meta': f\"{subj}_{act_name}\",\n",
        "                'subj': subj,\n",
        "                'act_id': act_id,\n",
        "            })\n",
        "        else:\n",
        "            # missing -> skip\n",
        "            pass\n",
        "\n",
        "    return trial_list\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.5) Windowing\n",
        "# ---------------------------------------------------------------------\n",
        "def trial_list_to_windows(trial_list, fs, win_sec=8.0, stride_sec=4.0, drop_last=True):\n",
        "    \"\"\"\n",
        "    TRAIN 전용: trial -> sliding windows\n",
        "    window 라벨은 trial 평균 rate로부터 생성:\n",
        "      rate_trial = count_total / total_duration\n",
        "      count_window = rate_trial * window_duration\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    assert win_len > 0 and stride > 0\n",
        "\n",
        "    windows = []\n",
        "    for item in trial_list:\n",
        "        x = item[\"data\"]  # (T,C)\n",
        "        T = x.shape[0]\n",
        "        total_count = float(item[\"count\"])\n",
        "        meta = item[\"meta\"]\n",
        "\n",
        "        total_dur = max(T / float(fs), 1e-6)\n",
        "        rate_trial = total_count / total_dur  # reps/s\n",
        "\n",
        "        if T < win_len:\n",
        "            win_dur = T / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x,\n",
        "                \"count\": rate_trial * win_dur,\n",
        "                \"meta\": f\"{meta}__win[0:{T}]\",\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        last_start = T - win_len\n",
        "        starts = list(range(0, last_start + 1, stride))\n",
        "\n",
        "        for st in starts:\n",
        "            ed = st + win_len\n",
        "            win_dur = win_len / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x[st:ed],\n",
        "                \"count\": rate_trial * win_dur,\n",
        "                \"meta\": f\"{meta}__win[{st}:{ed}]\",\n",
        "            })\n",
        "\n",
        "        if not drop_last:\n",
        "            last_st = starts[-1] + stride\n",
        "            if last_st < T:\n",
        "                ed = T\n",
        "                win_dur = (ed - last_st) / float(fs)\n",
        "                windows.append({\n",
        "                    \"data\": x[last_st:ed],\n",
        "                    \"count\": rate_trial * win_dur,\n",
        "                    \"meta\": f\"{meta}__win[{last_st}:{ed}]\",\n",
        "                })\n",
        "\n",
        "    return windows\n",
        "\n",
        "\n",
        "def predict_count_by_windowing(model, x_np, fs, win_sec, stride_sec, device, tau=1.0, batch_size=64):\n",
        "    \"\"\"\n",
        "    TEST 전용: trial -> windows inference -> window rate 평균 -> total count\n",
        "    x_np: (T,C) numpy (정규화된 상태)\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    T = x_np.shape[0]\n",
        "    total_dur = T / float(fs)\n",
        "\n",
        "    # short trial -> 1회 forward\n",
        "    if T <= win_len:\n",
        "        x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)  # (1,C,T)\n",
        "        with torch.no_grad():\n",
        "            rate_hat, _, _, _ = model(x_tensor, mask=None, tau=tau)\n",
        "        pred_count = float(rate_hat.item() * total_dur)\n",
        "        return pred_count\n",
        "\n",
        "    starts = list(range(0, T - win_len + 1, stride))\n",
        "    windows = np.stack([x_np[st:st + win_len] for st in starts], axis=0)  # (N, win_len, C)\n",
        "    xw = torch.tensor(windows, dtype=torch.float32).permute(0, 2, 1).to(device)  # (N,C,win_len)\n",
        "\n",
        "    rates = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, xw.shape[0], batch_size):\n",
        "            xb = xw[i:i + batch_size]\n",
        "            r_hat, _, _, _ = model(xb, mask=None, tau=tau)\n",
        "            rates.append(r_hat.detach().cpu().numpy())\n",
        "\n",
        "    rates = np.concatenate(rates, axis=0)  # (N,)\n",
        "    rate_mean = float(rates.mean())\n",
        "    pred_count = rate_mean * total_dur\n",
        "    return float(pred_count)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.8) Dataset / Collate\n",
        "# ---------------------------------------------------------------------\n",
        "class TrialDataset(Dataset):\n",
        "    def __init__(self, trial_list):\n",
        "        self.trials = trial_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trials)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.trials[idx]\n",
        "        data = torch.tensor(item['data'], dtype=torch.float32).transpose(0, 1)  # (C, T)\n",
        "        count = torch.tensor(item['count'], dtype=torch.float32)\n",
        "        return data, count, item['meta']\n",
        "\n",
        "\n",
        "def collate_variable_length(batch):\n",
        "    max_len = max([x[0].shape[1] for x in batch])\n",
        "    C = batch[0][0].shape[0]\n",
        "\n",
        "    padded_data, masks, counts, metas, lengths = [], [], [], [], []\n",
        "    for data, count, meta in batch:\n",
        "        T = data.shape[1]\n",
        "        lengths.append(T)\n",
        "\n",
        "        pad_size = max_len - T\n",
        "        if pad_size > 0:\n",
        "            pad = torch.zeros(C, pad_size)\n",
        "            d_padded = torch.cat([data, pad], dim=1)\n",
        "            mask = torch.cat([torch.ones(T), torch.zeros(pad_size)], dim=0)\n",
        "        else:\n",
        "            d_padded = data\n",
        "            mask = torch.ones(T)\n",
        "\n",
        "        padded_data.append(d_padded)\n",
        "        masks.append(mask)\n",
        "        counts.append(count)\n",
        "        metas.append(meta)\n",
        "\n",
        "    return {\n",
        "        \"data\": torch.stack(padded_data),         # (B, C, T_max)\n",
        "        \"mask\": torch.stack(masks),               # (B, T_max)\n",
        "        \"count\": torch.stack(counts),             # (B,)\n",
        "        \"length\": torch.tensor(lengths, dtype=torch.float32),  # (B,)\n",
        "        \"meta\": metas\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Model\n",
        "# ---------------------------------------------------------------------\n",
        "class ManifoldEncoder(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(input_ch, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, latent_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)            # (B,D,T)\n",
        "        z = z.transpose(1, 2)      # (B,T,D)\n",
        "        return z\n",
        "\n",
        "\n",
        "class ManifoldDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(latent_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, out_ch, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        zt = z.transpose(1, 2)     # (B,D,T)\n",
        "        x_hat = self.net(zt)       # (B,C,T)\n",
        "        return x_hat\n",
        "\n",
        "\n",
        "class MultiRateHead(nn.Module):\n",
        "    def __init__(self, latent_dim=16, hidden=64, K_max=6):\n",
        "        super().__init__()\n",
        "        self.K_max = K_max\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1 + K_max)  # [amp | phase_logits...]\n",
        "        )\n",
        "\n",
        "    def forward(self, z, tau=1.0):\n",
        "        out = self.net(z)                     # (B,T,1+K)\n",
        "        amp = F.softplus(out[..., 0])         # (B,T) >=0\n",
        "        phase_logits = out[..., 1:]           # (B,T,K)\n",
        "        phase = F.softmax(phase_logits / tau, dim=-1)\n",
        "        return amp, phase, phase_logits\n",
        "\n",
        "\n",
        "class KAutoCountModel(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16, K_max=6):\n",
        "        super().__init__()\n",
        "        self.encoder = ManifoldEncoder(input_ch, hidden_dim, latent_dim)\n",
        "        self.decoder = ManifoldDecoder(latent_dim, hidden_dim, input_ch)\n",
        "        self.rate_head = MultiRateHead(latent_dim, hidden=hidden_dim, K_max=K_max)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            b = self.rate_head.net[-1].bias\n",
        "            b.zero_()\n",
        "            b[0].fill_(-2.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def _masked_mean_time(x, mask=None, eps=1e-6):\n",
        "        if mask is None:\n",
        "            return x.mean(dim=1)\n",
        "        if x.dim() == 2:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        elif x.dim() == 3:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device).unsqueeze(-1)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported dim for masked mean: {x.dim()}\")\n",
        "\n",
        "    def forward(self, x, mask=None, tau=1.0):\n",
        "        z = self.encoder(x)              # (B,T,D)\n",
        "        x_hat = self.decoder(z)          # (B,C,T)\n",
        "\n",
        "        amp_t, phase_p, _ = self.rate_head(z, tau=tau)\n",
        "        micro_rate_t = amp_t             # (B,T)\n",
        "\n",
        "        p_bar = self._masked_mean_time(phase_p, mask)           # (B,K)\n",
        "        k_hat = 1.0 / (p_bar.pow(2).sum(dim=1) + 1e-6)          # (B,)\n",
        "\n",
        "        rep_rate_t = micro_rate_t / (k_hat.unsqueeze(1) + 1e-6) # (B,T)\n",
        "        if mask is not None:\n",
        "            rep_rate_t = rep_rate_t * mask\n",
        "\n",
        "        if mask is None:\n",
        "            avg_rep_rate = rep_rate_t.mean(dim=1)\n",
        "        else:\n",
        "            avg_rep_rate = (rep_rate_t * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-6)\n",
        "\n",
        "        aux = {\n",
        "            \"phase_p\": phase_p,          # (B,T,K)\n",
        "            \"rep_rate_t\": rep_rate_t,    # (B,T)\n",
        "            \"k_hat\": k_hat,              # (B,)\n",
        "        }\n",
        "        return avg_rep_rate, z, x_hat, aux\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Loss utils\n",
        "# ---------------------------------------------------------------------\n",
        "def masked_recon_mse(x_hat, x, mask, eps=1e-6):\n",
        "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
        "    mask_bc = mask.unsqueeze(1)              # (B,1,T)\n",
        "    se = (x_hat - x) ** 2                    # (B,C,T)\n",
        "    se = se * mask_bc\n",
        "    denom = (mask.sum() * x.shape[1]) + eps\n",
        "    return se.sum() / denom\n",
        "\n",
        "\n",
        "def temporal_smoothness(v, mask=None, eps=1e-6):\n",
        "    dv = torch.abs(v[:, 1:] - v[:, :-1])\n",
        "    if mask is None:\n",
        "        return dv.mean()\n",
        "    m = mask[:, 1:] * mask[:, :-1]\n",
        "    m = m.to(dtype=dv.dtype, device=dv.device)\n",
        "    return (dv * m).sum() / (m.sum() + eps)\n",
        "\n",
        "\n",
        "def phase_entropy_loss(phase_p, mask=None, eps=1e-8):\n",
        "    ent = -(phase_p * (phase_p + eps).log()).sum(dim=-1)  # (B,T)\n",
        "    if mask is None:\n",
        "        return ent.mean()\n",
        "    ent = ent * mask\n",
        "    return ent.sum() / (mask.sum() + eps)\n",
        "\n",
        "\n",
        "def effK_usage_loss(phase_p, mask=None, eps=1e-6):\n",
        "    if mask is None:\n",
        "        p_bar = phase_p.mean(dim=1)\n",
        "    else:\n",
        "        m = mask.to(dtype=phase_p.dtype, device=phase_p.device).unsqueeze(-1)\n",
        "        p_bar = (phase_p * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "    effK = 1.0 / (p_bar.pow(2).sum(dim=1) + eps)\n",
        "    return effK.mean()\n",
        "\n",
        "\n",
        "def compute_phase_entropy_mean(phase_p_np, eps=1e-8):\n",
        "    phase_p_np = np.asarray(phase_p_np, dtype=np.float32)  # (T,K)\n",
        "    ent_t = -(phase_p_np * np.log(phase_p_np + eps)).sum(axis=1)\n",
        "    return float(ent_t.mean())\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Train\n",
        "# ---------------------------------------------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, config, device):\n",
        "    model.train()\n",
        "    fs = config[\"fs\"]\n",
        "    tau = config.get(\"tau\", 1.0)\n",
        "\n",
        "    lam_recon = config.get(\"lambda_recon\", 1.0)\n",
        "    lam_smooth = config.get(\"lambda_smooth\", 0.05)\n",
        "    lam_phase_ent = config.get(\"lambda_phase_ent\", 0.01)\n",
        "    lam_effk = config.get(\"lambda_effk\", 0.005)\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"data\"].to(device)\n",
        "        mask = batch[\"mask\"].to(device)\n",
        "        y_count = batch[\"count\"].to(device)\n",
        "        length = batch[\"length\"].to(device)\n",
        "\n",
        "        duration = torch.clamp(length / fs, min=1e-6)\n",
        "        y_rate = y_count / duration\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        rate_hat, _, x_hat, aux = model(x, mask, tau=tau)\n",
        "\n",
        "        loss_rate = F.mse_loss(rate_hat, y_rate)\n",
        "        loss_recon = masked_recon_mse(x_hat, x, mask)\n",
        "        loss_smooth = temporal_smoothness(aux[\"rep_rate_t\"], mask)\n",
        "        loss_phase_ent = phase_entropy_loss(aux[\"phase_p\"], mask)\n",
        "        loss_effk = effK_usage_loss(aux[\"phase_p\"], mask)\n",
        "\n",
        "        loss = (loss_rate\n",
        "                + lam_recon * loss_recon\n",
        "                + lam_smooth * loss_smooth\n",
        "                + lam_phase_ent * loss_phase_ent\n",
        "                + lam_effk * loss_effk)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6) Main (4C2 Pairwise A2)\n",
        "# ---------------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"seed\": 42,\n",
        "        \"data_dir\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET\",\n",
        "        \"fs\": 50,\n",
        "        \"epochs\": 100,\n",
        "        \"lr\": 5e-4,\n",
        "        \"batch_size\": 64,\n",
        "\n",
        "        # windowing\n",
        "        \"win_sec\": 8.0,\n",
        "        \"stride_sec\": 4.0,\n",
        "        \"drop_last\": True,\n",
        "\n",
        "        # model\n",
        "        \"hidden_dim\": 128,\n",
        "        \"latent_dim\": 16,\n",
        "        \"K_max\": 6,\n",
        "\n",
        "        # loss\n",
        "        \"lambda_recon\": 1.0,\n",
        "        \"lambda_smooth\": 0.05,\n",
        "        \"lambda_phase_ent\": 0.01,\n",
        "        \"lambda_effk\": 0.0075,\n",
        "\n",
        "        \"tau\": 1.0,\n",
        "\n",
        "        \"BIDIRECTIONAL\": True,\n",
        "\n",
        "        \"COLUMN_NAMES\": [\n",
        "            'acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "            'ecg_1', 'ecg_2',\n",
        "            'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "            'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "            'mag_ankle_x', 'mag_ankle_y', 'mag_ankle_z',\n",
        "            'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "            'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z',\n",
        "            'mag_arm_x', 'mag_arm_y', 'mag_arm_z',\n",
        "            'activity_id'\n",
        "        ],\n",
        "        \"TARGET_ACTIVITIES_MAP\": {\n",
        "            6: 'Waist bends forward',\n",
        "            7: 'Frontal elevation of arms',\n",
        "            8: 'Knees bending',\n",
        "            12: 'Jump front & back'\n",
        "        },\n",
        "\n",
        "        # ✅ 모든 activity에서 동일 feature list (입력차원 고정)\n",
        "        \"ACT_FEATURE_MAP\": {\n",
        "            6: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            7: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            8: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            12: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                 'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                 'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                 'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                 'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "        },\n",
        "\n",
        "        # COUNT_TABLE[act_id][subject] = GT count\n",
        "        \"COUNT_TABLE\": {\n",
        "            6: {\n",
        "                \"subject1\": 21, \"subject2\": 19, \"subject3\": 21, \"subject4\": 20, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 20, \"subject8\": 21, \"subject9\": 21, \"subject10\": 20,\n",
        "            },\n",
        "            7: {\n",
        "                \"subject1\": 20, \"subject2\": 20, \"subject3\": 20, \"subject4\": 20, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 20, \"subject8\": 19, \"subject9\": 19, \"subject10\": 20,\n",
        "            },\n",
        "            8: {\n",
        "                \"subject1\": 20, \"subject2\": 21, \"subject3\": 21, \"subject4\": 19, \"subject5\": 20,\n",
        "                \"subject6\": 20, \"subject7\": 21, \"subject8\": 21, \"subject9\": 21, \"subject10\": 12,\n",
        "            },\n",
        "            12: {\n",
        "                \"subject1\": 20, \"subject2\": 22, \"subject3\": 21, \"subject4\": 21, \"subject5\": 20,\n",
        "                \"subject6\": 21, \"subject7\": 19, \"subject8\": 20, \"subject9\": 20, \"subject10\": 20,\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # -----------------------------\n",
        "    # sanity: feature 동일성 체크\n",
        "    # -----------------------------\n",
        "    feats_ref = None\n",
        "    for act_id, feats in CONFIG[\"ACT_FEATURE_MAP\"].items():\n",
        "        if feats_ref is None:\n",
        "            feats_ref = tuple(feats)\n",
        "        elif tuple(feats) != feats_ref:\n",
        "            raise ValueError(f\"[ERROR] ACT_FEATURE_MAP must be identical across activities. mismatch at act_id={act_id}\")\n",
        "\n",
        "    set_strict_seed(CONFIG[\"seed\"])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    full_data = load_mhealth_dataset(CONFIG[\"data_dir\"], CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"COLUMN_NAMES\"])\n",
        "    if not full_data:\n",
        "        print(\"[ERROR] dataset load failed\")\n",
        "        return\n",
        "\n",
        "    subjects = [f\"subject{i}\" for i in range(1, 11)]\n",
        "    act_ids = sorted(list(CONFIG[\"TARGET_ACTIVITIES_MAP\"].keys()))  # 4 activities\n",
        "    pairs = list(combinations(act_ids, 2))  # 4C2 = 6\n",
        "\n",
        "    # 실험 방향 리스트(6 or 12)\n",
        "    exp_dirs = []\n",
        "    for a, b in pairs:\n",
        "        exp_dirs.append((a, b))\n",
        "        if CONFIG[\"BIDIRECTIONAL\"]:\n",
        "            exp_dirs.append((b, a))\n",
        "\n",
        "    def gt_count(act_id, subj):\n",
        "        if act_id not in CONFIG[\"COUNT_TABLE\"]:\n",
        "            return None\n",
        "        return CONFIG[\"COUNT_TABLE\"][act_id].get(subj, None)\n",
        "\n",
        "    final_blocks = []\n",
        "    exp_idx = 0\n",
        "\n",
        "    # -----------------------------\n",
        "    # A2 loop: (actA->actB) x LOSO(subject)\n",
        "    # -----------------------------\n",
        "    for train_act, test_act in exp_dirs:\n",
        "        exp_idx += 1\n",
        "        train_name = CONFIG[\"TARGET_ACTIVITIES_MAP\"][train_act]\n",
        "        test_name  = CONFIG[\"TARGET_ACTIVITIES_MAP\"][test_act]\n",
        "\n",
        "        block_lines = []\n",
        "        abs_errs = []\n",
        "\n",
        "        for test_subj in subjects:\n",
        "            # -------------------------\n",
        "            # build labels (A2 rule)\n",
        "            # Train: train_act with subjects != test_subj\n",
        "            # Test : test_act  with subject == test_subj\n",
        "            # -------------------------\n",
        "            train_labels = []\n",
        "            for s in subjects:\n",
        "                if s == test_subj:\n",
        "                    continue\n",
        "                gtc = gt_count(train_act, s)\n",
        "                if gtc is None:\n",
        "                    continue\n",
        "                train_labels.append((s, train_act, gtc))\n",
        "\n",
        "            test_labels = []\n",
        "            gtc_test = gt_count(test_act, test_subj)\n",
        "            if gtc_test is not None:\n",
        "                test_labels.append((test_subj, test_act, gtc_test))\n",
        "\n",
        "            # missing labels -> write SKIP line\n",
        "            if len(train_labels) == 0 or len(test_labels) == 0:\n",
        "                block_lines.append(f\"{test_subj} | SKIP (missing COUNT_TABLE or data)\")\n",
        "                continue\n",
        "\n",
        "            # seed per fold\n",
        "            set_strict_seed(CONFIG[\"seed\"])\n",
        "\n",
        "            # trial-level load\n",
        "            train_trials = prepare_trial_list(train_labels, full_data, CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"ACT_FEATURE_MAP\"])\n",
        "            test_trials  = prepare_trial_list(test_labels,  full_data, CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"ACT_FEATURE_MAP\"])\n",
        "\n",
        "            if len(train_trials) == 0 or len(test_trials) == 0:\n",
        "                block_lines.append(f\"{test_subj} | SKIP (missing log segment)\")\n",
        "                continue\n",
        "\n",
        "            # train windows\n",
        "            train_windows = trial_list_to_windows(\n",
        "                train_trials,\n",
        "                fs=CONFIG[\"fs\"],\n",
        "                win_sec=CONFIG[\"win_sec\"],\n",
        "                stride_sec=CONFIG[\"stride_sec\"],\n",
        "                drop_last=CONFIG[\"drop_last\"]\n",
        "            )\n",
        "            if len(train_windows) == 0:\n",
        "                block_lines.append(f\"{test_subj} | SKIP (no windows)\")\n",
        "                continue\n",
        "\n",
        "            g = torch.Generator()\n",
        "            g.manual_seed(CONFIG[\"seed\"])\n",
        "            train_loader = DataLoader(\n",
        "                TrialDataset(train_windows),\n",
        "                batch_size=CONFIG[\"batch_size\"],\n",
        "                shuffle=True,\n",
        "                collate_fn=collate_variable_length,\n",
        "                generator=g,\n",
        "                num_workers=0\n",
        "            )\n",
        "\n",
        "            # model\n",
        "            input_ch = train_windows[0][\"data\"].shape[1]\n",
        "            model = KAutoCountModel(\n",
        "                input_ch=input_ch,\n",
        "                hidden_dim=CONFIG[\"hidden_dim\"],\n",
        "                latent_dim=CONFIG[\"latent_dim\"],\n",
        "                K_max=CONFIG[\"K_max\"]\n",
        "            ).to(device)\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
        "\n",
        "            # train (silent)\n",
        "            for _ in range(CONFIG[\"epochs\"]):\n",
        "                train_one_epoch(model, train_loader, optimizer, CONFIG, device)\n",
        "                scheduler.step()\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            # test_trials has exactly 1 item (test_subj, test_act)\n",
        "            item = test_trials[0]\n",
        "            x_np = item[\"data\"]\n",
        "            gt = float(item[\"count\"])\n",
        "\n",
        "            # windowing inference for count\n",
        "            pred = predict_count_by_windowing(\n",
        "                model,\n",
        "                x_np=x_np,\n",
        "                fs=CONFIG[\"fs\"],\n",
        "                win_sec=CONFIG[\"win_sec\"],\n",
        "                stride_sec=CONFIG[\"stride_sec\"],\n",
        "                device=device,\n",
        "                tau=CONFIG.get(\"tau\", 1.0),\n",
        "                batch_size=CONFIG.get(\"batch_size\", 64)\n",
        "            )\n",
        "            diff = pred - gt\n",
        "            abs_errs.append(abs(diff))\n",
        "\n",
        "            # full-trial forward for k_hat & entropy\n",
        "            x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                _, _, _, aux = model(x_tensor, mask=None, tau=CONFIG.get(\"tau\", 1.0))\n",
        "\n",
        "            phase_p = aux[\"phase_p\"].squeeze(0).detach().cpu().numpy()  # (T,K)\n",
        "            k_hat = float(aux[\"k_hat\"].item())\n",
        "            ent = compute_phase_entropy_mean(phase_p)\n",
        "\n",
        "            line = (f\"{test_subj} | GT={gt:.0f} | Pred(win)={pred:.2f} | Diff={diff:+.2f} | \"\n",
        "                    f\"k_hat(full)={k_hat:.2f} | phase_entropy(full)={ent:.3f}\")\n",
        "            block_lines.append(line)\n",
        "\n",
        "        mae = float(np.mean(abs_errs)) if len(abs_errs) > 0 else float(\"nan\")\n",
        "\n",
        "        final_blocks.append({\n",
        "            \"idx\": exp_idx,\n",
        "            \"title\": f\"{train_name} -> {test_name}\",\n",
        "            \"lines\": block_lines,\n",
        "            \"mae\": mae\n",
        "        })\n",
        "\n",
        "    # -----------------------------\n",
        "    # print ONCE at the end\n",
        "    # -----------------------------\n",
        "    print(\"\\n\" + \"=\" * 110)\n",
        "    print(\"A2 Pairwise Activity+Subject Transfer Results (4C2 pairs, LOSO-subject inside each pair)\")\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "    if len(final_blocks) == 0:\n",
        "        print(\"[No results] COUNT_TABLE이 충분히 채워졌는지 확인해줘.\")\n",
        "        print(\"=\" * 110)\n",
        "        return\n",
        "\n",
        "    for b in final_blocks:\n",
        "        print(f\"\\n{b['idx']}. {b['title']}  |  MAE={b['mae']:.3f}\")\n",
        "        for ln in b[\"lines\"]:\n",
        "            print(ln)\n",
        "\n",
        "    maes = [b[\"mae\"] for b in final_blocks if np.isfinite(b[\"mae\"])]\n",
        "    if len(maes) > 0:\n",
        "        print(\"\\n\" + \"-\" * 110)\n",
        "        print(f\"Overall Avg MAE={float(np.mean(maes)):.3f} | Std={float(np.std(maes)):.3f} | #pair_blocks={len(maes)}\")\n",
        "        print(\"-\" * 110)\n",
        "\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# A2 Pairwise (4C2) Full Code\n",
        "# - Unseen Activity + Unseen Subject\n",
        "# - For each activity pair (A->B):\n",
        "#     For each test_subject:\n",
        "#       Train on activity A using subjects except test_subject (windowed)\n",
        "#       Test on activity B using ONLY test_subject (windowing inference)\n",
        "#       k_hat / entropy: full-trial 1 forward for 기록\n",
        "# - 4C2=6 pairs, BIDIRECTIONAL=True -> 총 12 pair blocks\n",
        "# - 각 block 안에는 subject1~10 (LOSO) 결과 10줄\n",
        "# - 결과는 마지막에 한 번만 출력\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1) Strict Seeding\n",
        "# ---------------------------------------------------------------------\n",
        "def set_strict_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2) Data Loading\n",
        "# ---------------------------------------------------------------------\n",
        "def load_mhealth_dataset(data_dir, target_activities_map, column_names):\n",
        "    full_dataset = {}\n",
        "    file_list = sorted(glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\")))\n",
        "\n",
        "    if not file_list:\n",
        "        print(f\"[Warning] No mHealth logs found in {data_dir}\")\n",
        "        return {}\n",
        "\n",
        "    for file_path in file_list:\n",
        "        file_name = os.path.basename(file_path)\n",
        "        subj_part = file_name.split('.')[0]\n",
        "        try:\n",
        "            subj_id_num = int(''.join(filter(str.isdigit, subj_part)))\n",
        "            subj_key = f\"subject{subj_id_num}\"\n",
        "        except:\n",
        "            subj_key = subj_part\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "            df = df.iloc[:, :len(column_names)]\n",
        "            df.columns = column_names\n",
        "\n",
        "            subj_data = {}\n",
        "            for label_code, activity_name in target_activities_map.items():\n",
        "                activity_df = df[df['activity_id'] == label_code].copy()\n",
        "                if not activity_df.empty:\n",
        "                    subj_data[activity_name] = activity_df.drop(columns=['activity_id'])\n",
        "\n",
        "            full_dataset[subj_key] = subj_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_name}: {e}\")\n",
        "            pass\n",
        "\n",
        "    return full_dataset\n",
        "\n",
        "\n",
        "def prepare_trial_list(label_config, full_data, target_map, feature_map):\n",
        "    \"\"\"\n",
        "    label_config: list of (subj, act_id, gt_count)\n",
        "    return: list of dict trials\n",
        "    \"\"\"\n",
        "    trial_list = []\n",
        "    for subj, act_id, gt_count in label_config:\n",
        "        act_name = target_map.get(act_id)\n",
        "        feats = feature_map.get(act_id)\n",
        "\n",
        "        if subj in full_data and act_name in full_data[subj]:\n",
        "            raw_df = full_data[subj][act_name][feats]\n",
        "            raw_np = raw_df.values.astype(np.float32)\n",
        "\n",
        "            # Z-score (trial-wise)\n",
        "            mean = raw_np.mean(axis=0)\n",
        "            std = raw_np.std(axis=0) + 1e-6\n",
        "            norm_np = (raw_np - mean) / std\n",
        "\n",
        "            trial_list.append({\n",
        "                'data': norm_np,              # (T,C)\n",
        "                'count': float(gt_count),      # trial total count\n",
        "                'meta': f\"{subj}_{act_name}\",\n",
        "                'subj': subj,\n",
        "                'act_id': act_id,\n",
        "            })\n",
        "        else:\n",
        "            # missing -> skip\n",
        "            pass\n",
        "\n",
        "    return trial_list\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.5) Windowing\n",
        "# ---------------------------------------------------------------------\n",
        "def trial_list_to_windows(trial_list, fs, win_sec=8.0, stride_sec=4.0, drop_last=True):\n",
        "    \"\"\"\n",
        "    TRAIN 전용: trial -> sliding windows\n",
        "    window 라벨은 trial 평균 rate로부터 생성:\n",
        "      rate_trial = count_total / total_duration\n",
        "      count_window = rate_trial * window_duration\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    assert win_len > 0 and stride > 0\n",
        "\n",
        "    windows = []\n",
        "    for item in trial_list:\n",
        "        x = item[\"data\"]  # (T,C)\n",
        "        T = x.shape[0]\n",
        "        total_count = float(item[\"count\"])\n",
        "        meta = item[\"meta\"]\n",
        "\n",
        "        total_dur = max(T / float(fs), 1e-6)\n",
        "        rate_trial = total_count / total_dur  # reps/s\n",
        "\n",
        "        if T < win_len:\n",
        "            win_dur = T / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x,\n",
        "                \"count\": rate_trial * win_dur,\n",
        "                \"meta\": f\"{meta}__win[0:{T}]\",\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        last_start = T - win_len\n",
        "        starts = list(range(0, last_start + 1, stride))\n",
        "\n",
        "        for st in starts:\n",
        "            ed = st + win_len\n",
        "            win_dur = win_len / float(fs)\n",
        "            windows.append({\n",
        "                \"data\": x[st:ed],\n",
        "                \"count\": rate_trial * win_dur,\n",
        "                \"meta\": f\"{meta}__win[{st}:{ed}]\",\n",
        "            })\n",
        "\n",
        "        if not drop_last:\n",
        "            last_st = starts[-1] + stride\n",
        "            if last_st < T:\n",
        "                ed = T\n",
        "                win_dur = (ed - last_st) / float(fs)\n",
        "                windows.append({\n",
        "                    \"data\": x[last_st:ed],\n",
        "                    \"count\": rate_trial * win_dur,\n",
        "                    \"meta\": f\"{meta}__win[{last_st}:{ed}]\",\n",
        "                })\n",
        "\n",
        "    return windows\n",
        "\n",
        "\n",
        "def predict_count_by_windowing(model, x_np, fs, win_sec, stride_sec, device, tau=1.0, batch_size=64):\n",
        "    \"\"\"\n",
        "    TEST 전용: trial -> windows inference -> window rate 평균 -> total count\n",
        "    x_np: (T,C) numpy (정규화된 상태)\n",
        "    \"\"\"\n",
        "    win_len = int(round(win_sec * fs))\n",
        "    stride = int(round(stride_sec * fs))\n",
        "    T = x_np.shape[0]\n",
        "    total_dur = T / float(fs)\n",
        "\n",
        "    # short trial -> 1회 forward\n",
        "    if T <= win_len:\n",
        "        x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)  # (1,C,T)\n",
        "        with torch.no_grad():\n",
        "            rate_hat, _, _, _ = model(x_tensor, mask=None, tau=tau)\n",
        "        pred_count = float(rate_hat.item() * total_dur)\n",
        "        return pred_count\n",
        "\n",
        "    starts = list(range(0, T - win_len + 1, stride))\n",
        "    windows = np.stack([x_np[st:st + win_len] for st in starts], axis=0)  # (N, win_len, C)\n",
        "    xw = torch.tensor(windows, dtype=torch.float32).permute(0, 2, 1).to(device)  # (N,C,win_len)\n",
        "\n",
        "    rates = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, xw.shape[0], batch_size):\n",
        "            xb = xw[i:i + batch_size]\n",
        "            r_hat, _, _, _ = model(xb, mask=None, tau=tau)\n",
        "            rates.append(r_hat.detach().cpu().numpy())\n",
        "\n",
        "    rates = np.concatenate(rates, axis=0)  # (N,)\n",
        "    rate_mean = float(rates.mean())\n",
        "    pred_count = rate_mean * total_dur\n",
        "    return float(pred_count)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2.8) Dataset / Collate\n",
        "# ---------------------------------------------------------------------\n",
        "class TrialDataset(Dataset):\n",
        "    def __init__(self, trial_list):\n",
        "        self.trials = trial_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trials)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.trials[idx]\n",
        "        data = torch.tensor(item['data'], dtype=torch.float32).transpose(0, 1)  # (C, T)\n",
        "        count = torch.tensor(item['count'], dtype=torch.float32)\n",
        "        return data, count, item['meta']\n",
        "\n",
        "\n",
        "def collate_variable_length(batch):\n",
        "    max_len = max([x[0].shape[1] for x in batch])\n",
        "    C = batch[0][0].shape[0]\n",
        "\n",
        "    padded_data, masks, counts, metas, lengths = [], [], [], [], []\n",
        "    for data, count, meta in batch:\n",
        "        T = data.shape[1]\n",
        "        lengths.append(T)\n",
        "\n",
        "        pad_size = max_len - T\n",
        "        if pad_size > 0:\n",
        "            pad = torch.zeros(C, pad_size)\n",
        "            d_padded = torch.cat([data, pad], dim=1)\n",
        "            mask = torch.cat([torch.ones(T), torch.zeros(pad_size)], dim=0)\n",
        "        else:\n",
        "            d_padded = data\n",
        "            mask = torch.ones(T)\n",
        "\n",
        "        padded_data.append(d_padded)\n",
        "        masks.append(mask)\n",
        "        counts.append(count)\n",
        "        metas.append(meta)\n",
        "\n",
        "    return {\n",
        "        \"data\": torch.stack(padded_data),         # (B, C, T_max)\n",
        "        \"mask\": torch.stack(masks),               # (B, T_max)\n",
        "        \"count\": torch.stack(counts),             # (B,)\n",
        "        \"length\": torch.tensor(lengths, dtype=torch.float32),  # (B,)\n",
        "        \"meta\": metas\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3) Model\n",
        "# ---------------------------------------------------------------------\n",
        "class ManifoldEncoder(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(input_ch, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, latent_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)            # (B,D,T)\n",
        "        z = z.transpose(1, 2)      # (B,T,D)\n",
        "        return z\n",
        "\n",
        "\n",
        "class ManifoldDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(latent_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, out_ch, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        zt = z.transpose(1, 2)     # (B,D,T)\n",
        "        x_hat = self.net(zt)       # (B,C,T)\n",
        "        return x_hat\n",
        "\n",
        "\n",
        "class MultiRateHead(nn.Module):\n",
        "    def __init__(self, latent_dim=16, hidden=64, K_max=6):\n",
        "        super().__init__()\n",
        "        self.K_max = K_max\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 1 + K_max)  # [amp | phase_logits...]\n",
        "        )\n",
        "\n",
        "    def forward(self, z, tau=1.0):\n",
        "        out = self.net(z)                     # (B,T,1+K)\n",
        "        amp = F.softplus(out[..., 0])         # (B,T) >=0\n",
        "        phase_logits = out[..., 1:]           # (B,T,K)\n",
        "        phase = F.softmax(phase_logits / tau, dim=-1)\n",
        "        return amp, phase, phase_logits\n",
        "\n",
        "\n",
        "class KAutoCountModel(nn.Module):\n",
        "    def __init__(self, input_ch, hidden_dim=128, latent_dim=16, K_max=6):\n",
        "        super().__init__()\n",
        "        self.encoder = ManifoldEncoder(input_ch, hidden_dim, latent_dim)\n",
        "        self.decoder = ManifoldDecoder(latent_dim, hidden_dim, input_ch)\n",
        "        self.rate_head = MultiRateHead(latent_dim, hidden=hidden_dim, K_max=K_max)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            b = self.rate_head.net[-1].bias\n",
        "            b.zero_()\n",
        "            b[0].fill_(-2.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def _masked_mean_time(x, mask=None, eps=1e-6):\n",
        "        if mask is None:\n",
        "            return x.mean(dim=1)\n",
        "        if x.dim() == 2:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        elif x.dim() == 3:\n",
        "            m = mask.to(dtype=x.dtype, device=x.device).unsqueeze(-1)\n",
        "            return (x * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported dim for masked mean: {x.dim()}\")\n",
        "\n",
        "    def forward(self, x, mask=None, tau=1.0):\n",
        "        z = self.encoder(x)              # (B,T,D)\n",
        "        x_hat = self.decoder(z)          # (B,C,T)\n",
        "\n",
        "        amp_t, phase_p, _ = self.rate_head(z, tau=tau)\n",
        "        micro_rate_t = amp_t             # (B,T)\n",
        "\n",
        "        p_bar = self._masked_mean_time(phase_p, mask)           # (B,K)\n",
        "        k_hat = 1.0 / (p_bar.pow(2).sum(dim=1) + 1e-6)          # (B,)\n",
        "\n",
        "        rep_rate_t = micro_rate_t / (k_hat.unsqueeze(1) + 1e-6) # (B,T)\n",
        "        if mask is not None:\n",
        "            rep_rate_t = rep_rate_t * mask\n",
        "\n",
        "        if mask is None:\n",
        "            avg_rep_rate = rep_rate_t.mean(dim=1)\n",
        "        else:\n",
        "            avg_rep_rate = (rep_rate_t * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-6)\n",
        "\n",
        "        aux = {\n",
        "            \"phase_p\": phase_p,          # (B,T,K)\n",
        "            \"rep_rate_t\": rep_rate_t,    # (B,T)\n",
        "            \"k_hat\": k_hat,              # (B,)\n",
        "        }\n",
        "        return avg_rep_rate, z, x_hat, aux\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4) Loss utils\n",
        "# ---------------------------------------------------------------------\n",
        "def masked_recon_mse(x_hat, x, mask, eps=1e-6):\n",
        "    mask = mask.to(dtype=x.dtype, device=x.device)\n",
        "    mask_bc = mask.unsqueeze(1)              # (B,1,T)\n",
        "    se = (x_hat - x) ** 2                    # (B,C,T)\n",
        "    se = se * mask_bc\n",
        "    denom = (mask.sum() * x.shape[1]) + eps\n",
        "    return se.sum() / denom\n",
        "\n",
        "\n",
        "def temporal_smoothness(v, mask=None, eps=1e-6):\n",
        "    dv = torch.abs(v[:, 1:] - v[:, :-1])\n",
        "    if mask is None:\n",
        "        return dv.mean()\n",
        "    m = mask[:, 1:] * mask[:, :-1]\n",
        "    m = m.to(dtype=dv.dtype, device=dv.device)\n",
        "    return (dv * m).sum() / (m.sum() + eps)\n",
        "\n",
        "\n",
        "def phase_entropy_loss(phase_p, mask=None, eps=1e-8):\n",
        "    ent = -(phase_p * (phase_p + eps).log()).sum(dim=-1)  # (B,T)\n",
        "    if mask is None:\n",
        "        return ent.mean()\n",
        "    ent = ent * mask\n",
        "    return ent.sum() / (mask.sum() + eps)\n",
        "\n",
        "\n",
        "def effK_usage_loss(phase_p, mask=None, eps=1e-6):\n",
        "    if mask is None:\n",
        "        p_bar = phase_p.mean(dim=1)\n",
        "    else:\n",
        "        m = mask.to(dtype=phase_p.dtype, device=phase_p.device).unsqueeze(-1)\n",
        "        p_bar = (phase_p * m).sum(dim=1) / (m.sum(dim=1) + eps)\n",
        "    effK = 1.0 / (p_bar.pow(2).sum(dim=1) + eps)\n",
        "    return effK.mean()\n",
        "\n",
        "\n",
        "def compute_phase_entropy_mean(phase_p_np, eps=1e-8):\n",
        "    phase_p_np = np.asarray(phase_p_np, dtype=np.float32)  # (T,K)\n",
        "    ent_t = -(phase_p_np * np.log(phase_p_np + eps)).sum(axis=1)\n",
        "    return float(ent_t.mean())\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5) Train\n",
        "# ---------------------------------------------------------------------\n",
        "def train_one_epoch(model, loader, optimizer, config, device):\n",
        "    model.train()\n",
        "    fs = config[\"fs\"]\n",
        "    tau = config.get(\"tau\", 1.0)\n",
        "\n",
        "    lam_recon = config.get(\"lambda_recon\", 1.0)\n",
        "    lam_smooth = config.get(\"lambda_smooth\", 0.05)\n",
        "    lam_phase_ent = config.get(\"lambda_phase_ent\", 0.01)\n",
        "    lam_effk = config.get(\"lambda_effk\", 0.005)\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"data\"].to(device)\n",
        "        mask = batch[\"mask\"].to(device)\n",
        "        y_count = batch[\"count\"].to(device)\n",
        "        length = batch[\"length\"].to(device)\n",
        "\n",
        "        duration = torch.clamp(length / fs, min=1e-6)\n",
        "        y_rate = y_count / duration\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        rate_hat, _, x_hat, aux = model(x, mask, tau=tau)\n",
        "\n",
        "        loss_rate = F.mse_loss(rate_hat, y_rate)\n",
        "        loss_recon = masked_recon_mse(x_hat, x, mask)\n",
        "        loss_smooth = temporal_smoothness(aux[\"rep_rate_t\"], mask)\n",
        "        loss_phase_ent = phase_entropy_loss(aux[\"phase_p\"], mask)\n",
        "        loss_effk = effK_usage_loss(aux[\"phase_p\"], mask)\n",
        "\n",
        "        loss = (loss_rate\n",
        "                + lam_recon * loss_recon\n",
        "                + lam_smooth * loss_smooth\n",
        "                + lam_phase_ent * loss_phase_ent\n",
        "                + lam_effk * loss_effk)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6) Main (4C2 Pairwise A2)\n",
        "# ---------------------------------------------------------------------\n",
        "def main():\n",
        "    CONFIG = {\n",
        "        \"seed\": 42,\n",
        "        \"data_dir\": \"/content/drive/MyDrive/Colab Notebooks/HAR_data/MHEALTHDATASET\",\n",
        "        \"fs\": 50,\n",
        "        \"epochs\": 100,\n",
        "        \"lr\": 5e-4,\n",
        "        \"batch_size\": 64,\n",
        "\n",
        "        # windowing\n",
        "        \"win_sec\": 8.0,\n",
        "        \"stride_sec\": 4.0,\n",
        "        \"drop_last\": True,\n",
        "\n",
        "        # model\n",
        "        \"hidden_dim\": 128,\n",
        "        \"latent_dim\": 16,\n",
        "        \"K_max\": 6,\n",
        "\n",
        "        # loss\n",
        "        \"lambda_recon\": 1.0,\n",
        "        \"lambda_smooth\": 0.05,\n",
        "        \"lambda_phase_ent\": 0.01,\n",
        "        \"lambda_effk\": 0.0075,\n",
        "\n",
        "        \"tau\": 1.0,\n",
        "\n",
        "        \"BIDIRECTIONAL\": True,\n",
        "\n",
        "        \"COLUMN_NAMES\": [\n",
        "            'acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "            'ecg_1', 'ecg_2',\n",
        "            'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "            'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "            'mag_ankle_x', 'mag_ankle_y', 'mag_ankle_z',\n",
        "            'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "            'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z',\n",
        "            'mag_arm_x', 'mag_arm_y', 'mag_arm_z',\n",
        "            'activity_id'\n",
        "        ],\n",
        "        \"TARGET_ACTIVITIES_MAP\": {\n",
        "            4: 'Walking',\n",
        "            10: 'Jogging',\n",
        "            11: 'Running',\n",
        "        },\n",
        "\n",
        "        # ✅ 모든 activity에서 동일 feature list여야 pairwise 전이가 깔끔함(입력차원 고정)\n",
        "        \"ACT_FEATURE_MAP\": {\n",
        "            4: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            10: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "            11: ['acc_chest_x', 'acc_chest_y', 'acc_chest_z',\n",
        "                'acc_ankle_x', 'acc_ankle_y', 'acc_ankle_z',\n",
        "                'gyro_ankle_x', 'gyro_ankle_y', 'gyro_ankle_z',\n",
        "                'acc_arm_x', 'acc_arm_y', 'acc_arm_z',\n",
        "                'gyro_arm_x', 'gyro_arm_y', 'gyro_arm_z'],\n",
        "        },\n",
        "\n",
        "        # COUNT_TABLE[act_id][subject] = GT count\n",
        "        \"COUNT_TABLE\": {\n",
        "            4: {\n",
        "                \"subject1\": 113, \"subject2\": 99, \"subject3\": 104, \"subject4\": 112, \"subject5\": 109,\n",
        "                \"subject6\": 111, \"subject7\": 106, \"subject8\": 95, \"subject9\": 111, \"subject10\": 102,\n",
        "            },\n",
        "            10: {\n",
        "                \"subject1\": 157, \"subject2\": 161, \"subject3\": 154, \"subject4\": 154, \"subject5\": 160,\n",
        "                \"subject6\": 156, \"subject7\": 153, \"subject8\": 160, \"subject9\": 166, \"subject10\": 156,\n",
        "            },\n",
        "            11: {\n",
        "                \"subject1\": 165, \"subject2\": 158, \"subject3\": 174, \"subject4\": 163, \"subject5\": 157,\n",
        "                \"subject6\": 172, \"subject7\": 149, \"subject8\": 166, \"subject9\": 174, \"subject10\": 172,\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # -----------------------------\n",
        "    # sanity: feature 동일성 체크\n",
        "    # -----------------------------\n",
        "    feats_ref = None\n",
        "    for act_id, feats in CONFIG[\"ACT_FEATURE_MAP\"].items():\n",
        "        if feats_ref is None:\n",
        "            feats_ref = tuple(feats)\n",
        "        elif tuple(feats) != feats_ref:\n",
        "            raise ValueError(f\"[ERROR] ACT_FEATURE_MAP must be identical across activities. mismatch at act_id={act_id}\")\n",
        "\n",
        "    set_strict_seed(CONFIG[\"seed\"])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    full_data = load_mhealth_dataset(CONFIG[\"data_dir\"], CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"COLUMN_NAMES\"])\n",
        "    if not full_data:\n",
        "        print(\"[ERROR] dataset load failed\")\n",
        "        return\n",
        "\n",
        "    subjects = [f\"subject{i}\" for i in range(1, 11)]\n",
        "    act_ids = sorted(list(CONFIG[\"TARGET_ACTIVITIES_MAP\"].keys()))  # 4 activities\n",
        "    pairs = list(combinations(act_ids, 2))  # 4C2 = 6\n",
        "\n",
        "    # 실험 방향 리스트(6 or 12)\n",
        "    exp_dirs = []\n",
        "    for a, b in pairs:\n",
        "        exp_dirs.append((a, b))\n",
        "        if CONFIG[\"BIDIRECTIONAL\"]:\n",
        "            exp_dirs.append((b, a))\n",
        "\n",
        "    def gt_count(act_id, subj):\n",
        "        if act_id not in CONFIG[\"COUNT_TABLE\"]:\n",
        "            return None\n",
        "        return CONFIG[\"COUNT_TABLE\"][act_id].get(subj, None)\n",
        "\n",
        "    final_blocks = []\n",
        "    exp_idx = 0\n",
        "\n",
        "    # -----------------------------\n",
        "    # A2 loop: (actA->actB) x LOSO(subject)\n",
        "    # -----------------------------\n",
        "    for train_act, test_act in exp_dirs:\n",
        "        exp_idx += 1\n",
        "        train_name = CONFIG[\"TARGET_ACTIVITIES_MAP\"][train_act]\n",
        "        test_name  = CONFIG[\"TARGET_ACTIVITIES_MAP\"][test_act]\n",
        "\n",
        "        block_lines = []\n",
        "        abs_errs = []\n",
        "\n",
        "        for test_subj in subjects:\n",
        "            # -------------------------\n",
        "            # build labels (A2 rule)\n",
        "            # Train: train_act with subjects != test_subj\n",
        "            # Test : test_act  with subject == test_subj\n",
        "            # -------------------------\n",
        "            train_labels = []\n",
        "            for s in subjects:\n",
        "                if s == test_subj:\n",
        "                    continue\n",
        "                gtc = gt_count(train_act, s)\n",
        "                if gtc is None:\n",
        "                    continue\n",
        "                train_labels.append((s, train_act, gtc))\n",
        "\n",
        "            test_labels = []\n",
        "            gtc_test = gt_count(test_act, test_subj)\n",
        "            if gtc_test is not None:\n",
        "                test_labels.append((test_subj, test_act, gtc_test))\n",
        "\n",
        "            # missing labels -> write SKIP line\n",
        "            if len(train_labels) == 0 or len(test_labels) == 0:\n",
        "                block_lines.append(f\"{test_subj} | SKIP (missing COUNT_TABLE or data)\")\n",
        "                continue\n",
        "\n",
        "            # seed per fold\n",
        "            set_strict_seed(CONFIG[\"seed\"])\n",
        "\n",
        "            # trial-level load\n",
        "            train_trials = prepare_trial_list(train_labels, full_data, CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"ACT_FEATURE_MAP\"])\n",
        "            test_trials  = prepare_trial_list(test_labels,  full_data, CONFIG[\"TARGET_ACTIVITIES_MAP\"], CONFIG[\"ACT_FEATURE_MAP\"])\n",
        "\n",
        "            if len(train_trials) == 0 or len(test_trials) == 0:\n",
        "                block_lines.append(f\"{test_subj} | SKIP (missing log segment)\")\n",
        "                continue\n",
        "\n",
        "            # train windows\n",
        "            train_windows = trial_list_to_windows(\n",
        "                train_trials,\n",
        "                fs=CONFIG[\"fs\"],\n",
        "                win_sec=CONFIG[\"win_sec\"],\n",
        "                stride_sec=CONFIG[\"stride_sec\"],\n",
        "                drop_last=CONFIG[\"drop_last\"]\n",
        "            )\n",
        "            if len(train_windows) == 0:\n",
        "                block_lines.append(f\"{test_subj} | SKIP (no windows)\")\n",
        "                continue\n",
        "\n",
        "            g = torch.Generator()\n",
        "            g.manual_seed(CONFIG[\"seed\"])\n",
        "            train_loader = DataLoader(\n",
        "                TrialDataset(train_windows),\n",
        "                batch_size=CONFIG[\"batch_size\"],\n",
        "                shuffle=True,\n",
        "                collate_fn=collate_variable_length,\n",
        "                generator=g,\n",
        "                num_workers=0\n",
        "            )\n",
        "\n",
        "            # model\n",
        "            input_ch = train_windows[0][\"data\"].shape[1]\n",
        "            model = KAutoCountModel(\n",
        "                input_ch=input_ch,\n",
        "                hidden_dim=CONFIG[\"hidden_dim\"],\n",
        "                latent_dim=CONFIG[\"latent_dim\"],\n",
        "                K_max=CONFIG[\"K_max\"]\n",
        "            ).to(device)\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
        "\n",
        "            # train (silent)\n",
        "            for _ in range(CONFIG[\"epochs\"]):\n",
        "                train_one_epoch(model, train_loader, optimizer, CONFIG, device)\n",
        "                scheduler.step()\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            # test_trials has exactly 1 item (test_subj, test_act)\n",
        "            item = test_trials[0]\n",
        "            x_np = item[\"data\"]\n",
        "            gt = float(item[\"count\"])\n",
        "\n",
        "            # windowing inference for count\n",
        "            pred = predict_count_by_windowing(\n",
        "                model,\n",
        "                x_np=x_np,\n",
        "                fs=CONFIG[\"fs\"],\n",
        "                win_sec=CONFIG[\"win_sec\"],\n",
        "                stride_sec=CONFIG[\"stride_sec\"],\n",
        "                device=device,\n",
        "                tau=CONFIG.get(\"tau\", 1.0),\n",
        "                batch_size=CONFIG.get(\"batch_size\", 64)\n",
        "            )\n",
        "            diff = pred - gt\n",
        "            abs_errs.append(abs(diff))\n",
        "\n",
        "            # full-trial forward for k_hat & entropy\n",
        "            x_tensor = torch.tensor(x_np, dtype=torch.float32).transpose(0, 1).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                _, _, _, aux = model(x_tensor, mask=None, tau=CONFIG.get(\"tau\", 1.0))\n",
        "\n",
        "            phase_p = aux[\"phase_p\"].squeeze(0).detach().cpu().numpy()  # (T,K)\n",
        "            k_hat = float(aux[\"k_hat\"].item())\n",
        "            ent = compute_phase_entropy_mean(phase_p)\n",
        "\n",
        "            line = (f\"{test_subj} | GT={gt:.0f} | Pred(win)={pred:.2f} | Diff={diff:+.2f} | \"\n",
        "                    f\"k_hat(full)={k_hat:.2f} | phase_entropy(full)={ent:.3f}\")\n",
        "            block_lines.append(line)\n",
        "\n",
        "        mae = float(np.mean(abs_errs)) if len(abs_errs) > 0 else float(\"nan\")\n",
        "\n",
        "        final_blocks.append({\n",
        "            \"idx\": exp_idx,\n",
        "            \"title\": f\"{train_name} -> {test_name}\",\n",
        "            \"lines\": block_lines,\n",
        "            \"mae\": mae\n",
        "        })\n",
        "\n",
        "    # -----------------------------\n",
        "    # print ONCE at the end\n",
        "    # -----------------------------\n",
        "    print(\"\\n\" + \"=\" * 110)\n",
        "    print(\"A2 Pairwise Activity+Subject Transfer Results (4C2 pairs, LOSO-subject inside each pair)\")\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "    if len(final_blocks) == 0:\n",
        "        print(\"[No results] COUNT_TABLE이 충분히 채워졌는지 확인해줘.\")\n",
        "        print(\"=\" * 110)\n",
        "        return\n",
        "\n",
        "    for b in final_blocks:\n",
        "        print(f\"\\n{b['idx']}. {b['title']}  |  MAE={b['mae']:.3f}\")\n",
        "        for ln in b[\"lines\"]:\n",
        "            print(ln)\n",
        "\n",
        "    maes = [b[\"mae\"] for b in final_blocks if np.isfinite(b[\"mae\"])]\n",
        "    if len(maes) > 0:\n",
        "        print(\"\\n\" + \"-\" * 110)\n",
        "        print(f\"Overall Avg MAE={float(np.mean(maes)):.3f} | Std={float(np.std(maes)):.3f} | #pair_blocks={len(maes)}\")\n",
        "        print(\"-\" * 110)\n",
        "\n",
        "    print(\"=\" * 110)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAR0PFSE0PZ_",
        "outputId": "7611ec5d-50cb-4e84-95ff-aa41c024118a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================================================================================================\n",
            "A2 Pairwise Activity+Subject Transfer Results (4C2 pairs, LOSO-subject inside each pair)\n",
            "==============================================================================================================\n",
            "\n",
            "1. Walking -> Jogging  |  MAE=52.840\n",
            "subject1 | GT=157 | Pred(win)=102.21 | Diff=-54.79 | k_hat(full)=2.31 | phase_entropy(full)=0.635\n",
            "subject2 | GT=161 | Pred(win)=96.42 | Diff=-64.58 | k_hat(full)=2.51 | phase_entropy(full)=0.716\n",
            "subject3 | GT=154 | Pred(win)=96.80 | Diff=-57.20 | k_hat(full)=2.32 | phase_entropy(full)=0.742\n",
            "subject4 | GT=154 | Pred(win)=102.68 | Diff=-51.32 | k_hat(full)=2.25 | phase_entropy(full)=0.701\n",
            "subject5 | GT=160 | Pred(win)=98.36 | Diff=-61.64 | k_hat(full)=2.47 | phase_entropy(full)=0.688\n",
            "subject6 | GT=156 | Pred(win)=144.03 | Diff=-11.97 | k_hat(full)=1.71 | phase_entropy(full)=0.623\n",
            "subject7 | GT=153 | Pred(win)=102.50 | Diff=-50.50 | k_hat(full)=2.35 | phase_entropy(full)=0.709\n",
            "subject8 | GT=160 | Pred(win)=93.09 | Diff=-66.91 | k_hat(full)=2.33 | phase_entropy(full)=0.673\n",
            "subject9 | GT=166 | Pred(win)=116.04 | Diff=-49.96 | k_hat(full)=2.01 | phase_entropy(full)=0.726\n",
            "subject10 | GT=156 | Pred(win)=96.47 | Diff=-59.53 | k_hat(full)=2.24 | phase_entropy(full)=0.736\n",
            "\n",
            "2. Jogging -> Walking  |  MAE=39.891\n",
            "subject1 | GT=113 | Pred(win)=146.98 | Diff=+33.98 | k_hat(full)=1.24 | phase_entropy(full)=0.355\n",
            "subject2 | GT=99 | Pred(win)=162.78 | Diff=+63.78 | k_hat(full)=1.82 | phase_entropy(full)=0.471\n",
            "subject3 | GT=104 | Pred(win)=126.28 | Diff=+22.28 | k_hat(full)=1.47 | phase_entropy(full)=0.505\n",
            "subject4 | GT=112 | Pred(win)=140.91 | Diff=+28.91 | k_hat(full)=1.37 | phase_entropy(full)=0.431\n",
            "subject5 | GT=109 | Pred(win)=146.55 | Diff=+37.55 | k_hat(full)=1.51 | phase_entropy(full)=0.452\n",
            "subject6 | GT=111 | Pred(win)=156.21 | Diff=+45.21 | k_hat(full)=1.54 | phase_entropy(full)=0.375\n",
            "subject7 | GT=106 | Pred(win)=140.09 | Diff=+34.09 | k_hat(full)=1.42 | phase_entropy(full)=0.500\n",
            "subject8 | GT=95 | Pred(win)=146.65 | Diff=+51.65 | k_hat(full)=1.61 | phase_entropy(full)=0.462\n",
            "subject9 | GT=111 | Pred(win)=148.92 | Diff=+37.92 | k_hat(full)=1.79 | phase_entropy(full)=0.481\n",
            "subject10 | GT=102 | Pred(win)=145.53 | Diff=+43.53 | k_hat(full)=1.48 | phase_entropy(full)=0.471\n",
            "\n",
            "3. Walking -> Running  |  MAE=55.670\n",
            "subject1 | GT=165 | Pred(win)=100.91 | Diff=-64.09 | k_hat(full)=2.32 | phase_entropy(full)=0.634\n",
            "subject2 | GT=158 | Pred(win)=98.49 | Diff=-59.51 | k_hat(full)=2.51 | phase_entropy(full)=0.712\n",
            "subject3 | GT=174 | Pred(win)=102.58 | Diff=-71.42 | k_hat(full)=2.22 | phase_entropy(full)=0.730\n",
            "subject4 | GT=163 | Pred(win)=117.15 | Diff=-45.85 | k_hat(full)=1.99 | phase_entropy(full)=0.618\n",
            "subject5 | GT=157 | Pred(win)=108.78 | Diff=-48.22 | k_hat(full)=2.37 | phase_entropy(full)=0.670\n",
            "subject6 | GT=172 | Pred(win)=102.69 | Diff=-69.31 | k_hat(full)=2.11 | phase_entropy(full)=0.780\n",
            "subject7 | GT=149 | Pred(win)=114.64 | Diff=-34.36 | k_hat(full)=2.15 | phase_entropy(full)=0.703\n",
            "subject8 | GT=166 | Pred(win)=104.98 | Diff=-61.02 | k_hat(full)=2.24 | phase_entropy(full)=0.618\n",
            "subject9 | GT=174 | Pred(win)=139.88 | Diff=-34.12 | k_hat(full)=1.62 | phase_entropy(full)=0.532\n",
            "subject10 | GT=172 | Pred(win)=103.18 | Diff=-68.82 | k_hat(full)=2.13 | phase_entropy(full)=0.721\n",
            "\n",
            "4. Running -> Walking  |  MAE=58.609\n",
            "subject1 | GT=113 | Pred(win)=159.63 | Diff=+46.63 | k_hat(full)=1.54 | phase_entropy(full)=0.367\n",
            "subject2 | GT=99 | Pred(win)=171.87 | Diff=+72.87 | k_hat(full)=1.95 | phase_entropy(full)=0.439\n",
            "subject3 | GT=104 | Pred(win)=157.51 | Diff=+53.51 | k_hat(full)=1.28 | phase_entropy(full)=0.347\n",
            "subject4 | GT=112 | Pred(win)=182.10 | Diff=+70.10 | k_hat(full)=1.18 | phase_entropy(full)=0.281\n",
            "subject5 | GT=109 | Pred(win)=151.67 | Diff=+42.67 | k_hat(full)=1.40 | phase_entropy(full)=0.385\n",
            "subject6 | GT=111 | Pred(win)=162.37 | Diff=+51.37 | k_hat(full)=1.69 | phase_entropy(full)=0.310\n",
            "subject7 | GT=106 | Pred(win)=173.31 | Diff=+67.31 | k_hat(full)=1.23 | phase_entropy(full)=0.311\n",
            "subject8 | GT=95 | Pred(win)=160.06 | Diff=+65.06 | k_hat(full)=1.38 | phase_entropy(full)=0.361\n",
            "subject9 | GT=111 | Pred(win)=166.10 | Diff=+55.10 | k_hat(full)=1.55 | phase_entropy(full)=0.353\n",
            "subject10 | GT=102 | Pred(win)=163.48 | Diff=+61.48 | k_hat(full)=1.24 | phase_entropy(full)=0.314\n",
            "\n",
            "5. Jogging -> Running  |  MAE=13.572\n",
            "subject1 | GT=165 | Pred(win)=167.22 | Diff=+2.22 | k_hat(full)=1.19 | phase_entropy(full)=0.282\n",
            "subject2 | GT=158 | Pred(win)=172.02 | Diff=+14.02 | k_hat(full)=1.73 | phase_entropy(full)=0.472\n",
            "subject3 | GT=174 | Pred(win)=141.91 | Diff=-32.09 | k_hat(full)=1.36 | phase_entropy(full)=0.368\n",
            "subject4 | GT=163 | Pred(win)=150.30 | Diff=-12.70 | k_hat(full)=1.37 | phase_entropy(full)=0.369\n",
            "subject5 | GT=157 | Pred(win)=149.25 | Diff=-7.75 | k_hat(full)=1.51 | phase_entropy(full)=0.428\n",
            "subject6 | GT=172 | Pred(win)=158.59 | Diff=-13.41 | k_hat(full)=1.61 | phase_entropy(full)=0.363\n",
            "subject7 | GT=149 | Pred(win)=140.54 | Diff=-8.46 | k_hat(full)=1.45 | phase_entropy(full)=0.441\n",
            "subject8 | GT=166 | Pred(win)=158.89 | Diff=-7.11 | k_hat(full)=1.50 | phase_entropy(full)=0.428\n",
            "subject9 | GT=174 | Pred(win)=186.45 | Diff=+12.45 | k_hat(full)=1.62 | phase_entropy(full)=0.404\n",
            "subject10 | GT=172 | Pred(win)=146.48 | Diff=-25.52 | k_hat(full)=1.54 | phase_entropy(full)=0.435\n",
            "\n",
            "6. Running -> Jogging  |  MAE=19.565\n",
            "subject1 | GT=157 | Pred(win)=153.38 | Diff=-3.62 | k_hat(full)=1.67 | phase_entropy(full)=0.329\n",
            "subject2 | GT=161 | Pred(win)=170.06 | Diff=+9.06 | k_hat(full)=1.96 | phase_entropy(full)=0.339\n",
            "subject3 | GT=154 | Pred(win)=169.88 | Diff=+15.88 | k_hat(full)=1.35 | phase_entropy(full)=0.281\n",
            "subject4 | GT=154 | Pred(win)=191.67 | Diff=+37.67 | k_hat(full)=1.27 | phase_entropy(full)=0.244\n",
            "subject5 | GT=160 | Pred(win)=185.90 | Diff=+25.90 | k_hat(full)=1.32 | phase_entropy(full)=0.273\n",
            "subject6 | GT=156 | Pred(win)=165.44 | Diff=+9.44 | k_hat(full)=1.86 | phase_entropy(full)=0.441\n",
            "subject7 | GT=153 | Pred(win)=182.99 | Diff=+29.99 | k_hat(full)=1.30 | phase_entropy(full)=0.267\n",
            "subject8 | GT=160 | Pred(win)=151.99 | Diff=-8.01 | k_hat(full)=1.38 | phase_entropy(full)=0.337\n",
            "subject9 | GT=166 | Pred(win)=195.14 | Diff=+29.14 | k_hat(full)=1.51 | phase_entropy(full)=0.258\n",
            "subject10 | GT=156 | Pred(win)=182.95 | Diff=+26.95 | k_hat(full)=1.32 | phase_entropy(full)=0.252\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Overall Avg MAE=40.025 | Std=17.667 | #pair_blocks=6\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "==============================================================================================================\n"
          ]
        }
      ]
    }
  ]
}